{
 "metadata": {
  "name": "",
  "signature": "sha256:3b6544516ea6aebec2e1cebdddf2f82a5bc7843eca0e083a5316e91d28ac7ea0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Node(object):\n",
      "    LEFT = 0\n",
      "    RIGHT = 1\n",
      "    \n",
      "    def __init__(self, cutpoint=None, attr=None):\n",
      "        self.cutpoint = cutpoint\n",
      "        self.attr = attr\n",
      "        self.value = None\n",
      "        self.left = None\n",
      "        self.right = None\n",
      "        \n",
      "    def attach(self, node, leftright):\n",
      "        if leftright == self.LEFT:\n",
      "            self.left = node\n",
      "        else:\n",
      "            self.right = node\n",
      "        \n",
      "    def __repr__(self):\n",
      "        return 'If {0} < {1}'.format(self.attr, self.cutpoint) if self.cutpoint else str(self.value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ExtraTreeEnsemble(object):\n",
      "    \n",
      "    def __init__(self, n_estimators=10, max_features=None, max_depth=5, min_samples_split=2):\n",
      "        self.trees = [ExtraTree(max_features, max_depth, min_samples_split) for i in range(n_estimators)]\n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        for tree in self.trees:\n",
      "            tree.fit(X, y)\n",
      "            \n",
      "    def predict(self, X):\n",
      "        return np.mean([tree.predict(X) for tree in self.trees], axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ExtraTree(object):   \n",
      "    def __init__(self, max_features=None, max_depth=5, min_samples_split=2, random_state=None):\n",
      "        self.smin = min_samples_split\n",
      "        self.K = max_features\n",
      "        self.max_depth = max_depth\n",
      "        self.root = None\n",
      "        self.rng = numpy.random.RandomState(random_state)\n",
      "        \n",
      "    def fit(self, X, y):\n",
      "        self.root = self.build(X, y, self.K, self.smin, self.max_depth)\n",
      "        \n",
      "    def find_leaf(self, x):\n",
      "        node = self.root\n",
      "        while node.cutpoint != None:\n",
      "            node = node.left if x[node.attr] < node.cutpoint else node.right   \n",
      "        return node.value\n",
      "        \n",
      "    def predict(self, X):\n",
      "        out = np.empty((X.shape[0],))\n",
      "        for i, sample in enumerate(X):\n",
      "            out[i] = self.find_leaf(sample)\n",
      "        return out\n",
      "        \n",
      "    def isconstant_attribute(self, subset, attr, threshold=1e-7):\n",
      "        return np.abs(np.max(subset[:,attr]) - np.min(subset[:,attr])) < threshold\n",
      "  \n",
      "    def isconstant_output(self, Y, threshold=1e-7):\n",
      "        return np.abs(np.max(Y) - np.min(Y)) < threshold\n",
      "    \n",
      "    def nonconstant_attributes(self, subset, candidates):\n",
      "        return [attr for attr in candidates if not self.isconstant_attribute(subset, attr)]\n",
      "   \n",
      "    def build(self, X, Y, K, smin, max_depth):\n",
      "        stack, root = [], None\n",
      "        stack.append((None, 0, 1, np.array(range(X.shape[0]))))\n",
      "        allattributes = range(X.shape[1])\n",
      "        \n",
      "        while len(stack) > 0:\n",
      "            parent, leftright, depth, subset_idx = stack.pop()\n",
      "            subset = X[subset_idx]\n",
      "            candidates = self.nonconstant_attributes(subset, allattributes)\n",
      "            \n",
      "            if depth >= max_depth or subset.shape[0] < smin \\\n",
      "                or len(candidates) == 0 or self.isconstant_output(Y[subset_idx]):\n",
      "                node = Node()\n",
      "                node.value = np.mean(Y[subset_idx])\n",
      "                parent.attach(node, leftright)\n",
      "            else:     \n",
      "                # Select randomly K attributes, {a1,...,aK},\n",
      "                # without replacement, among all (non constant in S)\n",
      "                # candidate attributes;\n",
      "                rnd_attributes = candidates #if K == None else self.rng.choice(candidates, K, replace=False)\n",
      "\n",
      "                # Generate K random splits\n",
      "                rnd_splits = [self.split(subset, attr) for attr in rnd_attributes]\n",
      "                # Select a split s\u2217 such that score is max among all splits\n",
      "                scores = [self.score(Y, subset_idx, subset[:,attr] < split, subset[:,attr] > split)\n",
      "                             for attr, split in zip(rnd_attributes, rnd_splits)]\n",
      "                best_split = np.argmax(scores)\n",
      "                best_attr = rnd_attributes[best_split]\n",
      "                best_split_value = rnd_splits[best_split]\n",
      "\n",
      "                # Create a node with the split s\u2217, attach tl and tr as left and right subtrees\n",
      "                node = Node(best_split_value, best_attr)\n",
      "                if parent:\n",
      "                    parent.attach(node, leftright)\n",
      "                else:\n",
      "                    root = node\n",
      "\n",
      "                # Split S into subsets Sl and Sr\n",
      "                # Build from these subsets\n",
      "                stack.append((node, node.LEFT,  depth+1, subset_idx[subset[:,best_attr] < best_split_value]))\n",
      "                stack.append((node, node.RIGHT, depth+1, subset_idx[subset[:,best_attr] > best_split_value]))\n",
      "        return root\n",
      "                \n",
      "    def split(self, subset, attr):\n",
      "        \"\"\" Draw a random split point for the given attribute\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : ndarray\n",
      "                 Training set\n",
      "        attr : int\n",
      "               Attribute index\n",
      "               \n",
      "        Returns\n",
      "        -------\n",
      "        double:\n",
      "            A random split point uniformly at random within\n",
      "            the empirical attribute range.\n",
      "        \"\"\"\n",
      "        minattr = np.min(subset[:,attr], axis=0)\n",
      "        maxattr = np.max(subset[:,attr], axis=0)\n",
      "        return self.rng.uniform(minattr, maxattr)\n",
      "                \n",
      "    def score(self, Y, S, Sl, Sr):\n",
      "        \"\"\" Relative variance reduction \n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        Y : ndarray\n",
      "            Outputs\n",
      "        S : ndarray\n",
      "            Training set\n",
      "        Sl : ndarray\n",
      "            indices for the left partition\n",
      "        Sr : ndarray\n",
      "            indices for the right partition\n",
      "            \n",
      "        Returns\n",
      "        -------\n",
      "        double: \n",
      "            The relative variance reduction score as defined in Appendix A\n",
      "            \n",
      "        \"\"\"\n",
      "        varout = np.var(Y[S])\n",
      "        yleft = Y[Sl]\n",
      "        yright = Y[Sr]\n",
      "        Slen = float(len(S))\n",
      "        Sl_len = float(len(yleft))\n",
      "        Sr_len = float(len(yright))\n",
      "\n",
      "        return (varout - (Sl_len/Slen)*np.var(yleft) - (Sr_len/Slen)*np.var(yright))#/varout"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import asciitree\n",
      "from sklearn.datasets import load_boston\n",
      "boston = load_boston()\n",
      "tree = ExtraTree()#random_state=1234)\n",
      "tree.fit(boston.data, boston.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print asciitree.draw_tree(tree.root, child_iter=lambda node: [node.right, node.left] if node.cutpoint else [])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "If 12 < 16.1963390612\n",
        "  +--If 8 < 15.2832844055\n",
        "  |  +--If 5 < 5.87523268807\n",
        "  |  |  +--If 11 < 119.405458946\n",
        "  |  |  |  +--14.9121212121\n",
        "  |  |  |  +--11.9\n",
        "  |  |  +--If 11 < 385.807685056\n",
        "  |  |     +--10.5133333333\n",
        "  |  |     +--11.1866666667\n",
        "  |  +--If 8 < 2.67992808111\n",
        "  |     +--If 7 < 2.74267791276\n",
        "  |     |  +--17.7678571429\n",
        "  |     |  +--15.18\n",
        "  |     +--If 6 < 96.6432859794\n",
        "  |        +--17.3\n",
        "  |        +--18.3333333333\n",
        "  +--If 4 < 0.54405933451\n",
        "     +--If 2 < 14.7660476699\n",
        "     |  +--If 10 < 20.2815295686\n",
        "     |  |  +--19.2166666667\n",
        "     |  |  +--24.4208955224\n",
        "     |  +--If 4 < 0.554305138672\n",
        "     |     +--29.4434782609\n",
        "     |     +--21.47\n",
        "     +--If 1 < 16.2681652694\n",
        "        +--If 8 < 3.84383211697\n",
        "        |  +--27.7734177215\n",
        "        |  +--28.603125\n",
        "        +--If 9 < 435.84389163\n",
        "           +--22.62\n",
        "           +--24.7879432624\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tree.predict(boston.data[:10])\n",
      "print boston.target[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 28.603125    24.78794326  24.78794326  24.78794326  24.78794326\n",
        "  24.78794326  24.78794326  17.76785714  17.76785714  17.76785714]\n",
        "[ 24.   21.6  34.7  33.4  36.2  28.7  22.9  27.1  16.5  18.9]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import mean_squared_error\n",
      "import sklearn.ensemble\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.5, random_state=1234)\n",
      "#reg = sklearn.ensemble.ExtraTreesRegressor(max_features=None, max_depth=5, min_samples_split=2, n_estimators=10)\n",
      "reg = ExtraTreeEnsemble(max_features=None, max_depth=5, min_samples_split=2, n_estimators=10)\n",
      "reg.fit(X_train, y_train)\n",
      "y_pred = reg.predict(X_test)\n",
      "\n",
      "mean_squared_error(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "30.210714151830381"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    }
   ],
   "metadata": {}
  }
 ]
}